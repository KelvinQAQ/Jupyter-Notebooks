{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f286526b160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "读取MNIST数据\n",
    "\"\"\"\n",
    "\n",
    "def load_data():\n",
    "\n",
    "    img_test_data = open('GANs_MNIST/t10k-images.idx3-ubyte')\n",
    "    test_label = open('GANs_MNIST/t10k-labels.idx1-ubyte')\n",
    "    img_train_data = open('GANs_MNIST/train-images.idx3-ubyte')\n",
    "    train_label = open('GANs_MNIST/train-labels.idx1-ubyte')\n",
    "\n",
    "    num_test = 10000\n",
    "    num_train = 60000\n",
    "    length = 28 * 28\n",
    "\n",
    "    array_test_data = np.fromfile(img_test_data, dtype=np.uint8)\n",
    "    array_test_label = np.fromfile(test_label, dtype=np.uint8)\n",
    "    array_train_data = np.fromfile(img_train_data, dtype=np.uint8)\n",
    "    array_train_label = np.fromfile(train_label, dtype=np.uint8)\n",
    "    \n",
    "#     t_imgs = np.transpose(array_test_data[16:].reshape(28, 28, 10000), (2, 0, 1))\n",
    "#     t_labels = array_test_label[8:]\n",
    "#     tr_imgs = np.transpose(array_train_data[16:].reshape(28, 28, 60000), (2, 0, 1))\n",
    "#     tr_labels = array_train_label[8:]\n",
    "\n",
    "    t_imgs = []\n",
    "    t_labels = array_test_label[8:]\n",
    "    tr_imgs = []\n",
    "    tr_labels = array_train_label[8:]\n",
    "\n",
    "    for i in range(num_test):\n",
    "        t_imgs.append(array_test_data[16 + i * length : 16 + (i + 1) * length].reshape(28, 28))\n",
    "\n",
    "    for i in range(num_train):\n",
    "        tr_imgs.append(array_train_data[16 + i * length : 16 + (i + 1) * length].reshape(28, 28))\n",
    "        \n",
    "    tr_imgs = np.array(tr_imgs)\n",
    "    t_imgs = np.array(t_imgs)\n",
    "    \n",
    "    return (tr_imgs, tr_labels), (t_imgs, t_labels)\n",
    "\n",
    "(tr_i, tr_l), (t_i, t_l) = load_data()\n",
    "print(tr_l[65])\n",
    "plt.imshow(tr_i[65], cmap='gray')\n",
    "print(tr_i.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "\n",
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(128*7*7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(64, (5, 5), padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(1, (5, 5), padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "            Conv2D(64, (5, 5),\n",
    "            padding='same',\n",
    "            input_shape=(28, 28, 1))\n",
    "            )\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (5, 5)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def generator_containing_discriminator(g, d):\n",
    "    model = Sequential()\n",
    "    model.add(g)\n",
    "    d.trainable = False\n",
    "    model.add(d)\n",
    "    return model\n",
    "\n",
    "\n",
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, 0]\n",
    "    return image\n",
    "\n",
    "\n",
    "def train(BATCH_SIZE):\n",
    "    (X_train, y_train), (X_test, y_test) = load_data()\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train[:, :, :, None]\n",
    "    X_test = X_test[:, :, :, None]\n",
    "    # X_train = X_train.reshape((X_train.shape, 1) + X_train.shape[1:])\n",
    "    d = discriminator_model()\n",
    "    g = generator_model()\n",
    "    d_on_g = generator_containing_discriminator(g, d)\n",
    "    d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    d_on_g.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    d.trainable = True\n",
    "    d.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "    for epoch in range(100):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "            noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = g.predict(noise, verbose=0)\n",
    "            if index % 20 == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5+127.5\n",
    "                Image.fromarray(image.astype(np.uint8)).save(\n",
    "                    str(epoch)+\"_\"+str(index)+\".png\")\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            d_loss = d.train_on_batch(X, y)\n",
    "            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "            noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "            d.trainable = False\n",
    "            g_loss = d_on_g.train_on_batch(noise, [1] * BATCH_SIZE)\n",
    "            d.trainable = True\n",
    "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "            if index % 10 == 9:\n",
    "                g.save_weights('generator', True)\n",
    "                d.save_weights('discriminator', True)\n",
    "\n",
    "\n",
    "def generate(BATCH_SIZE, nice=False):\n",
    "    g = generator_model()\n",
    "    g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    g.load_weights('generator')\n",
    "    if nice:\n",
    "        d = discriminator_model()\n",
    "        d.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "        d.load_weights('discriminator')\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE*20, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        d_pret = d.predict(generated_images, verbose=1)\n",
    "        index = np.arange(0, BATCH_SIZE*20)\n",
    "        index.resize((BATCH_SIZE*20, 1))\n",
    "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "        nice_images = np.zeros((BATCH_SIZE,) + generated_images.shape[1:3], dtype=np.float32)\n",
    "        nice_images = nice_images[:, :, :, None]\n",
    "        for i in range(BATCH_SIZE):\n",
    "            idx = int(pre_with_index[i][1])\n",
    "            nice_images[i, :, :, 0] = generated_images[idx, :, :, 0]\n",
    "        image = combine_images(nice_images)\n",
    "    else:\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\n",
    "        \"generated_image.png\")\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mode\", type=str)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    parser.add_argument(\"--nice\", dest=\"nice\", action=\"store_true\")\n",
    "    parser.set_defaults(nice=False)\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = get_args()\n",
    "    if args.mode == \"train\":\n",
    "        train(BATCH_SIZE=args.batch_size)\n",
    "    elif args.mode == \"generate\":\n",
    "        generate(BATCH_SIZE=args.batch_size, nice=args.nice)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
